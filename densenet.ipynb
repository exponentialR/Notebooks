{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "import sys\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, nChannels, growthRate):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        interChannels = 4*growthRate\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels)\n",
    "        self.conv1 = nn.Conv2d(nChannels, interChannels, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(interChannels)\n",
    "        self.conv2 = nn.Conv2d(interChannels, growthRate, kernel_size=3,\n",
    "                               padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out = torch.cat((x, out), 1)\n",
    "        return out\n",
    "\n",
    "class SingleLayer(nn.Module):\n",
    "    def __init__(self, nChannels, growthRate):\n",
    "        super(SingleLayer, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels)\n",
    "        self.conv1 = nn.Conv2d(nChannels, growthRate, kernel_size=3,\n",
    "                               padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = torch.cat((x, out), 1)\n",
    "        return out\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, nChannels, nOutChannels):\n",
    "        super(Transition, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels)\n",
    "        self.conv1 = nn.Conv2d(nChannels, nOutChannels, kernel_size=1,\n",
    "                               bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, growthRate, depth, reduction, nClasses, bottleneck):\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        nDenseBlocks = (depth-4) // 3\n",
    "        if bottleneck:\n",
    "            nDenseBlocks //= 2\n",
    "\n",
    "        nChannels = 2*growthRate\n",
    "        self.conv1 = nn.Conv2d(3, nChannels, kernel_size=3, padding=1,\n",
    "                               bias=False)\n",
    "        self.dense1 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n",
    "        nChannels += nDenseBlocks*growthRate\n",
    "        nOutChannels = int(math.floor(nChannels*reduction))\n",
    "        self.trans1 = Transition(nChannels, nOutChannels)\n",
    "\n",
    "        nChannels = nOutChannels\n",
    "        self.dense2 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n",
    "        nChannels += nDenseBlocks*growthRate\n",
    "        nOutChannels = int(math.floor(nChannels*reduction))\n",
    "        self.trans2 = Transition(nChannels, nOutChannels)\n",
    "\n",
    "        nChannels = nOutChannels\n",
    "        self.dense3 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n",
    "        nChannels += nDenseBlocks*growthRate\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(nChannels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(nChannels, nClasses)\n",
    "        self.nChannels = nChannels\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_dense(self, nChannels, growthRate, nDenseBlocks, bottleneck):\n",
    "        layers = []\n",
    "        for i in range(int(nDenseBlocks)):\n",
    "            if bottleneck:\n",
    "                layers.append(Bottleneck(nChannels, growthRate))\n",
    "            else:\n",
    "                layers.append(SingleLayer(nChannels, growthRate))\n",
    "            nChannels += growthRate\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         out = x.view(x.size(0), -1)\n",
    "        out = self.conv1(x)\n",
    "        out = self.trans1(self.dense1(out))\n",
    "        out = self.trans2(self.dense2(out))\n",
    "        out = self.dense3(out)\n",
    "        print(out.shape)\n",
    "        out = self.relu(self.bn1(out))\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(-1, self.nChannels)\n",
    "        print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= DenseNet(12, 100, 0.5, 10, bottleneck=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet(\n",
      "  (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (dense1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(132, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(156, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(168, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(180, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(204, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (trans1): Transition(\n",
      "    (bn1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv1): Conv2d(216, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (dense2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(132, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(156, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(168, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(180, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(204, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(216, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(228, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(228, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(240, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(252, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(264, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(276, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(276, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (trans2): Transition(\n",
      "    (bn1): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv1): Conv2d(300, 150, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (dense3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (bn1): BatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(150, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (bn1): BatchNorm2d(162, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(162, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (bn1): BatchNorm2d(174, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(174, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (bn1): BatchNorm2d(186, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(186, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (bn1): BatchNorm2d(198, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(198, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (bn1): BatchNorm2d(210, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(210, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (bn1): BatchNorm2d(222, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(222, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (bn1): BatchNorm2d(234, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(234, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (bn1): BatchNorm2d(246, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(246, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (bn1): BatchNorm2d(258, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(258, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (bn1): BatchNorm2d(270, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(270, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (bn1): BatchNorm2d(282, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(282, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (bn1): BatchNorm2d(294, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(294, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (bn1): BatchNorm2d(306, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(306, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (bn1): BatchNorm2d(318, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(318, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (bn1): BatchNorm2d(330, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(330, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (bn1): BatchNorm2d(342, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (fc): Linear(in_features=342, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 342, 25, 25])\n",
      "torch.Size([18, 342])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [32, 24, 100, 100]             648\n",
      "       BatchNorm2d-2         [32, 24, 100, 100]              48\n",
      "            Conv2d-3         [32, 48, 100, 100]           1,152\n",
      "       BatchNorm2d-4         [32, 48, 100, 100]              96\n",
      "            Conv2d-5         [32, 12, 100, 100]           5,184\n",
      "        Bottleneck-6         [32, 36, 100, 100]               0\n",
      "       BatchNorm2d-7         [32, 36, 100, 100]              72\n",
      "            Conv2d-8         [32, 48, 100, 100]           1,728\n",
      "       BatchNorm2d-9         [32, 48, 100, 100]              96\n",
      "           Conv2d-10         [32, 12, 100, 100]           5,184\n",
      "       Bottleneck-11         [32, 48, 100, 100]               0\n",
      "      BatchNorm2d-12         [32, 48, 100, 100]              96\n",
      "           Conv2d-13         [32, 48, 100, 100]           2,304\n",
      "      BatchNorm2d-14         [32, 48, 100, 100]              96\n",
      "           Conv2d-15         [32, 12, 100, 100]           5,184\n",
      "       Bottleneck-16         [32, 60, 100, 100]               0\n",
      "      BatchNorm2d-17         [32, 60, 100, 100]             120\n",
      "           Conv2d-18         [32, 48, 100, 100]           2,880\n",
      "      BatchNorm2d-19         [32, 48, 100, 100]              96\n",
      "           Conv2d-20         [32, 12, 100, 100]           5,184\n",
      "       Bottleneck-21         [32, 72, 100, 100]               0\n",
      "      BatchNorm2d-22         [32, 72, 100, 100]             144\n",
      "           Conv2d-23         [32, 48, 100, 100]           3,456\n",
      "      BatchNorm2d-24         [32, 48, 100, 100]              96\n",
      "           Conv2d-25         [32, 12, 100, 100]           5,184\n",
      "       Bottleneck-26         [32, 84, 100, 100]               0\n",
      "      BatchNorm2d-27         [32, 84, 100, 100]             168\n",
      "           Conv2d-28         [32, 48, 100, 100]           4,032\n",
      "      BatchNorm2d-29         [32, 48, 100, 100]              96\n",
      "           Conv2d-30         [32, 12, 100, 100]           5,184\n",
      "       Bottleneck-31         [32, 96, 100, 100]               0\n",
      "      BatchNorm2d-32         [32, 96, 100, 100]             192\n",
      "           Conv2d-33         [32, 48, 100, 100]           4,608\n",
      "      BatchNorm2d-34         [32, 48, 100, 100]              96\n",
      "           Conv2d-35         [32, 12, 100, 100]           5,184\n",
      "       Bottleneck-36        [32, 108, 100, 100]               0\n",
      "      BatchNorm2d-37        [32, 108, 100, 100]             216\n",
      "           Conv2d-38         [32, 48, 100, 100]           5,184\n",
      "      BatchNorm2d-39         [32, 48, 100, 100]              96\n",
      "           Conv2d-40         [32, 12, 100, 100]           5,184\n",
      "       Bottleneck-41        [32, 120, 100, 100]               0\n",
      "      BatchNorm2d-42        [32, 120, 100, 100]             240\n",
      "           Conv2d-43         [32, 48, 100, 100]           5,760\n",
      "      BatchNorm2d-44         [32, 48, 100, 100]              96\n",
      "           Conv2d-45         [32, 12, 100, 100]           5,184\n",
      "       Bottleneck-46        [32, 132, 100, 100]               0\n",
      "      BatchNorm2d-47        [32, 132, 100, 100]             264\n",
      "           Conv2d-48         [32, 48, 100, 100]           6,336\n",
      "      BatchNorm2d-49         [32, 48, 100, 100]              96\n",
      "           Conv2d-50         [32, 12, 100, 100]           5,184\n",
      "       Bottleneck-51        [32, 144, 100, 100]               0\n",
      "      BatchNorm2d-52        [32, 144, 100, 100]             288\n",
      "           Conv2d-53         [32, 48, 100, 100]           6,912\n",
      "      BatchNorm2d-54         [32, 48, 100, 100]              96\n",
      "           Conv2d-55         [32, 12, 100, 100]           5,184\n",
      "       Bottleneck-56        [32, 156, 100, 100]               0\n",
      "      BatchNorm2d-57        [32, 156, 100, 100]             312\n",
      "           Conv2d-58         [32, 48, 100, 100]           7,488\n",
      "      BatchNorm2d-59         [32, 48, 100, 100]              96\n",
      "           Conv2d-60         [32, 12, 100, 100]           5,184\n",
      "       Bottleneck-61        [32, 168, 100, 100]               0\n",
      "      BatchNorm2d-62        [32, 168, 100, 100]             336\n",
      "           Conv2d-63         [32, 48, 100, 100]           8,064\n",
      "      BatchNorm2d-64         [32, 48, 100, 100]              96\n",
      "           Conv2d-65         [32, 12, 100, 100]           5,184\n",
      "       Bottleneck-66        [32, 180, 100, 100]               0\n",
      "      BatchNorm2d-67        [32, 180, 100, 100]             360\n",
      "           Conv2d-68         [32, 48, 100, 100]           8,640\n",
      "      BatchNorm2d-69         [32, 48, 100, 100]              96\n",
      "           Conv2d-70         [32, 12, 100, 100]           5,184\n",
      "       Bottleneck-71        [32, 192, 100, 100]               0\n",
      "      BatchNorm2d-72        [32, 192, 100, 100]             384\n",
      "           Conv2d-73         [32, 48, 100, 100]           9,216\n",
      "      BatchNorm2d-74         [32, 48, 100, 100]              96\n",
      "           Conv2d-75         [32, 12, 100, 100]           5,184\n",
      "       Bottleneck-76        [32, 204, 100, 100]               0\n",
      "      BatchNorm2d-77        [32, 204, 100, 100]             408\n",
      "           Conv2d-78         [32, 48, 100, 100]           9,792\n",
      "      BatchNorm2d-79         [32, 48, 100, 100]              96\n",
      "           Conv2d-80         [32, 12, 100, 100]           5,184\n",
      "       Bottleneck-81        [32, 216, 100, 100]               0\n",
      "      BatchNorm2d-82        [32, 216, 100, 100]             432\n",
      "           Conv2d-83        [32, 108, 100, 100]          23,328\n",
      "       Transition-84          [32, 108, 50, 50]               0\n",
      "      BatchNorm2d-85          [32, 108, 50, 50]             216\n",
      "           Conv2d-86           [32, 48, 50, 50]           5,184\n",
      "      BatchNorm2d-87           [32, 48, 50, 50]              96\n",
      "           Conv2d-88           [32, 12, 50, 50]           5,184\n",
      "       Bottleneck-89          [32, 120, 50, 50]               0\n",
      "      BatchNorm2d-90          [32, 120, 50, 50]             240\n",
      "           Conv2d-91           [32, 48, 50, 50]           5,760\n",
      "      BatchNorm2d-92           [32, 48, 50, 50]              96\n",
      "           Conv2d-93           [32, 12, 50, 50]           5,184\n",
      "       Bottleneck-94          [32, 132, 50, 50]               0\n",
      "      BatchNorm2d-95          [32, 132, 50, 50]             264\n",
      "           Conv2d-96           [32, 48, 50, 50]           6,336\n",
      "      BatchNorm2d-97           [32, 48, 50, 50]              96\n",
      "           Conv2d-98           [32, 12, 50, 50]           5,184\n",
      "       Bottleneck-99          [32, 144, 50, 50]               0\n",
      "     BatchNorm2d-100          [32, 144, 50, 50]             288\n",
      "          Conv2d-101           [32, 48, 50, 50]           6,912\n",
      "     BatchNorm2d-102           [32, 48, 50, 50]              96\n",
      "          Conv2d-103           [32, 12, 50, 50]           5,184\n",
      "      Bottleneck-104          [32, 156, 50, 50]               0\n",
      "     BatchNorm2d-105          [32, 156, 50, 50]             312\n",
      "          Conv2d-106           [32, 48, 50, 50]           7,488\n",
      "     BatchNorm2d-107           [32, 48, 50, 50]              96\n",
      "          Conv2d-108           [32, 12, 50, 50]           5,184\n",
      "      Bottleneck-109          [32, 168, 50, 50]               0\n",
      "     BatchNorm2d-110          [32, 168, 50, 50]             336\n",
      "          Conv2d-111           [32, 48, 50, 50]           8,064\n",
      "     BatchNorm2d-112           [32, 48, 50, 50]              96\n",
      "          Conv2d-113           [32, 12, 50, 50]           5,184\n",
      "      Bottleneck-114          [32, 180, 50, 50]               0\n",
      "     BatchNorm2d-115          [32, 180, 50, 50]             360\n",
      "          Conv2d-116           [32, 48, 50, 50]           8,640\n",
      "     BatchNorm2d-117           [32, 48, 50, 50]              96\n",
      "          Conv2d-118           [32, 12, 50, 50]           5,184\n",
      "      Bottleneck-119          [32, 192, 50, 50]               0\n",
      "     BatchNorm2d-120          [32, 192, 50, 50]             384\n",
      "          Conv2d-121           [32, 48, 50, 50]           9,216\n",
      "     BatchNorm2d-122           [32, 48, 50, 50]              96\n",
      "          Conv2d-123           [32, 12, 50, 50]           5,184\n",
      "      Bottleneck-124          [32, 204, 50, 50]               0\n",
      "     BatchNorm2d-125          [32, 204, 50, 50]             408\n",
      "          Conv2d-126           [32, 48, 50, 50]           9,792\n",
      "     BatchNorm2d-127           [32, 48, 50, 50]              96\n",
      "          Conv2d-128           [32, 12, 50, 50]           5,184\n",
      "      Bottleneck-129          [32, 216, 50, 50]               0\n",
      "     BatchNorm2d-130          [32, 216, 50, 50]             432\n",
      "          Conv2d-131           [32, 48, 50, 50]          10,368\n",
      "     BatchNorm2d-132           [32, 48, 50, 50]              96\n",
      "          Conv2d-133           [32, 12, 50, 50]           5,184\n",
      "      Bottleneck-134          [32, 228, 50, 50]               0\n",
      "     BatchNorm2d-135          [32, 228, 50, 50]             456\n",
      "          Conv2d-136           [32, 48, 50, 50]          10,944\n",
      "     BatchNorm2d-137           [32, 48, 50, 50]              96\n",
      "          Conv2d-138           [32, 12, 50, 50]           5,184\n",
      "      Bottleneck-139          [32, 240, 50, 50]               0\n",
      "     BatchNorm2d-140          [32, 240, 50, 50]             480\n",
      "          Conv2d-141           [32, 48, 50, 50]          11,520\n",
      "     BatchNorm2d-142           [32, 48, 50, 50]              96\n",
      "          Conv2d-143           [32, 12, 50, 50]           5,184\n",
      "      Bottleneck-144          [32, 252, 50, 50]               0\n",
      "     BatchNorm2d-145          [32, 252, 50, 50]             504\n",
      "          Conv2d-146           [32, 48, 50, 50]          12,096\n",
      "     BatchNorm2d-147           [32, 48, 50, 50]              96\n",
      "          Conv2d-148           [32, 12, 50, 50]           5,184\n",
      "      Bottleneck-149          [32, 264, 50, 50]               0\n",
      "     BatchNorm2d-150          [32, 264, 50, 50]             528\n",
      "          Conv2d-151           [32, 48, 50, 50]          12,672\n",
      "     BatchNorm2d-152           [32, 48, 50, 50]              96\n",
      "          Conv2d-153           [32, 12, 50, 50]           5,184\n",
      "      Bottleneck-154          [32, 276, 50, 50]               0\n",
      "     BatchNorm2d-155          [32, 276, 50, 50]             552\n",
      "          Conv2d-156           [32, 48, 50, 50]          13,248\n",
      "     BatchNorm2d-157           [32, 48, 50, 50]              96\n",
      "          Conv2d-158           [32, 12, 50, 50]           5,184\n",
      "      Bottleneck-159          [32, 288, 50, 50]               0\n",
      "     BatchNorm2d-160          [32, 288, 50, 50]             576\n",
      "          Conv2d-161           [32, 48, 50, 50]          13,824\n",
      "     BatchNorm2d-162           [32, 48, 50, 50]              96\n",
      "          Conv2d-163           [32, 12, 50, 50]           5,184\n",
      "      Bottleneck-164          [32, 300, 50, 50]               0\n",
      "     BatchNorm2d-165          [32, 300, 50, 50]             600\n",
      "          Conv2d-166          [32, 150, 50, 50]          45,000\n",
      "      Transition-167          [32, 150, 25, 25]               0\n",
      "     BatchNorm2d-168          [32, 150, 25, 25]             300\n",
      "          Conv2d-169           [32, 48, 25, 25]           7,200\n",
      "     BatchNorm2d-170           [32, 48, 25, 25]              96\n",
      "          Conv2d-171           [32, 12, 25, 25]           5,184\n",
      "      Bottleneck-172          [32, 162, 25, 25]               0\n",
      "     BatchNorm2d-173          [32, 162, 25, 25]             324\n",
      "          Conv2d-174           [32, 48, 25, 25]           7,776\n",
      "     BatchNorm2d-175           [32, 48, 25, 25]              96\n",
      "          Conv2d-176           [32, 12, 25, 25]           5,184\n",
      "      Bottleneck-177          [32, 174, 25, 25]               0\n",
      "     BatchNorm2d-178          [32, 174, 25, 25]             348\n",
      "          Conv2d-179           [32, 48, 25, 25]           8,352\n",
      "     BatchNorm2d-180           [32, 48, 25, 25]              96\n",
      "          Conv2d-181           [32, 12, 25, 25]           5,184\n",
      "      Bottleneck-182          [32, 186, 25, 25]               0\n",
      "     BatchNorm2d-183          [32, 186, 25, 25]             372\n",
      "          Conv2d-184           [32, 48, 25, 25]           8,928\n",
      "     BatchNorm2d-185           [32, 48, 25, 25]              96\n",
      "          Conv2d-186           [32, 12, 25, 25]           5,184\n",
      "      Bottleneck-187          [32, 198, 25, 25]               0\n",
      "     BatchNorm2d-188          [32, 198, 25, 25]             396\n",
      "          Conv2d-189           [32, 48, 25, 25]           9,504\n",
      "     BatchNorm2d-190           [32, 48, 25, 25]              96\n",
      "          Conv2d-191           [32, 12, 25, 25]           5,184\n",
      "      Bottleneck-192          [32, 210, 25, 25]               0\n",
      "     BatchNorm2d-193          [32, 210, 25, 25]             420\n",
      "          Conv2d-194           [32, 48, 25, 25]          10,080\n",
      "     BatchNorm2d-195           [32, 48, 25, 25]              96\n",
      "          Conv2d-196           [32, 12, 25, 25]           5,184\n",
      "      Bottleneck-197          [32, 222, 25, 25]               0\n",
      "     BatchNorm2d-198          [32, 222, 25, 25]             444\n",
      "          Conv2d-199           [32, 48, 25, 25]          10,656\n",
      "     BatchNorm2d-200           [32, 48, 25, 25]              96\n",
      "          Conv2d-201           [32, 12, 25, 25]           5,184\n",
      "      Bottleneck-202          [32, 234, 25, 25]               0\n",
      "     BatchNorm2d-203          [32, 234, 25, 25]             468\n",
      "          Conv2d-204           [32, 48, 25, 25]          11,232\n",
      "     BatchNorm2d-205           [32, 48, 25, 25]              96\n",
      "          Conv2d-206           [32, 12, 25, 25]           5,184\n",
      "      Bottleneck-207          [32, 246, 25, 25]               0\n",
      "     BatchNorm2d-208          [32, 246, 25, 25]             492\n",
      "          Conv2d-209           [32, 48, 25, 25]          11,808\n",
      "     BatchNorm2d-210           [32, 48, 25, 25]              96\n",
      "          Conv2d-211           [32, 12, 25, 25]           5,184\n",
      "      Bottleneck-212          [32, 258, 25, 25]               0\n",
      "     BatchNorm2d-213          [32, 258, 25, 25]             516\n",
      "          Conv2d-214           [32, 48, 25, 25]          12,384\n",
      "     BatchNorm2d-215           [32, 48, 25, 25]              96\n",
      "          Conv2d-216           [32, 12, 25, 25]           5,184\n",
      "      Bottleneck-217          [32, 270, 25, 25]               0\n",
      "     BatchNorm2d-218          [32, 270, 25, 25]             540\n",
      "          Conv2d-219           [32, 48, 25, 25]          12,960\n",
      "     BatchNorm2d-220           [32, 48, 25, 25]              96\n",
      "          Conv2d-221           [32, 12, 25, 25]           5,184\n",
      "      Bottleneck-222          [32, 282, 25, 25]               0\n",
      "     BatchNorm2d-223          [32, 282, 25, 25]             564\n",
      "          Conv2d-224           [32, 48, 25, 25]          13,536\n",
      "     BatchNorm2d-225           [32, 48, 25, 25]              96\n",
      "          Conv2d-226           [32, 12, 25, 25]           5,184\n",
      "      Bottleneck-227          [32, 294, 25, 25]               0\n",
      "     BatchNorm2d-228          [32, 294, 25, 25]             588\n",
      "          Conv2d-229           [32, 48, 25, 25]          14,112\n",
      "     BatchNorm2d-230           [32, 48, 25, 25]              96\n",
      "          Conv2d-231           [32, 12, 25, 25]           5,184\n",
      "      Bottleneck-232          [32, 306, 25, 25]               0\n",
      "     BatchNorm2d-233          [32, 306, 25, 25]             612\n",
      "          Conv2d-234           [32, 48, 25, 25]          14,688\n",
      "     BatchNorm2d-235           [32, 48, 25, 25]              96\n",
      "          Conv2d-236           [32, 12, 25, 25]           5,184\n",
      "      Bottleneck-237          [32, 318, 25, 25]               0\n",
      "     BatchNorm2d-238          [32, 318, 25, 25]             636\n",
      "          Conv2d-239           [32, 48, 25, 25]          15,264\n",
      "     BatchNorm2d-240           [32, 48, 25, 25]              96\n",
      "          Conv2d-241           [32, 12, 25, 25]           5,184\n",
      "      Bottleneck-242          [32, 330, 25, 25]               0\n",
      "     BatchNorm2d-243          [32, 330, 25, 25]             660\n",
      "          Conv2d-244           [32, 48, 25, 25]          15,840\n",
      "     BatchNorm2d-245           [32, 48, 25, 25]              96\n",
      "          Conv2d-246           [32, 12, 25, 25]           5,184\n",
      "      Bottleneck-247          [32, 342, 25, 25]               0\n",
      "     BatchNorm2d-248          [32, 342, 25, 25]             684\n",
      "            ReLU-249          [32, 342, 25, 25]               0\n",
      "================================================================\n",
      "Total params: 765,732\n",
      "Trainable params: 765,732\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.66\n",
      "Forward/backward pass size (MB): 21415.10\n",
      "Params size (MB): 2.92\n",
      "Estimated Total Size (MB): 21421.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (3, 100, 100), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(/Users/solua1/Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer.add_graph(model, (30, 60, 196))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.randn(16, 3, 60, 196)\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/solua1/opt/anaconda3/envs/ge-mac/lib/python3.6/site-packages/ipykernel_launcher.py:61: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([96, 342])\n",
      "torch.Size([96, 342])\n",
      "torch.Size([96, 342])\n"
     ]
    }
   ],
   "source": [
    "grid = torchvision.utils.make_grid(image)\n",
    "writer.add_image('image', grid, 0)\n",
    "writer.add_graph(model, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TENSORBOARD_BINARY'] = '/path/to/envs/my_env/bin/tensorboard'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find '/path/to/envs/my_env/bin/tensorboard' (set by\n",
       "the `TENSORBOARD_BINARY` environment variable). Please ensure that\n",
       "your PATH contains an executable `tensorboard` program, or explicitly\n",
       "specify the path to a TensorBoard binary by setting the\n",
       "`TENSORBOARD_BINARY` environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
